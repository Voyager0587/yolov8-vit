# 小白项目指南：深度学习模型训练与部署

## 项目概述

该项目包含两个主要的深度学习任务：

1.  **图像分类 (Image Classification)**：训练一个模型来识别图片中的物体属于哪个预定义的类别。
2.  **目标检测 (Object Detection)**：训练一个模型 (看起来是YOLO) 来在图片中定位物体并识别它们的类别。

项目中还包含了一些辅助工具，例如：
*   从URL下载图片。
*   与阿里云OSS对象存储服务交互（上传、下载文件，获取文件URL）。
*   生成PASCAL VOC格式的XML标注文件，这通常用于目标检测任务。
*   一个通用的模型包装器，用于在预训练模型的基础上添加自定义的分类头。

## 一、 环境搭建与准备

在开始之前，你需要配置好你的开发环境。

1.  **Python 环境**:
    *   确保你安装了 Python (推荐 Python 3.8+)。
    *   建议使用虚拟环境 (如 `venv` 或 `conda`) 来管理项目依赖，避免不同项目间的库版本冲突。
        *   创建虚拟环境 (以 `venv` 为例):
            ```bash
            python -m venv myenv
            ```
        *   激活虚拟环境:
            *   Windows: `myenv\Scripts\activate`
            *   macOS/Linux: `source myenv/bin/activate`

2.  **安装依赖库**:
    项目中使用到的主要 Python 库包括 `requests`, `cv2` (OpenCV), `oss2` (阿里云OSS SDK), `numpy`, `timm` (PyTorch Image Models), `torch` (PyTorch), `flask_sse` (看样子可能用于某种实时日志或消息推送，但在核心训练逻辑中可能不是必需的), `xml.etree.ElementTree` (Python内置)。
    你可以使用 `requirements.txt` 文件（已在上一步骤中讨论并创建）来安装所有依赖：
    ```bash
    pip install -r requirements.txt
    ```
    请注意，PyTorch (`torch`, `torchvision`, `torchaudio`) 的安装可能需要根据你的操作系统和CUDA版本（如果你有NVIDIA GPU并希望使用GPU加速）进行特定配置。你可以访问 [PyTorch官网](https://pytorch.org/get-started/locally/) 获取适合你环境的安装命令。

3.  **代码结构 (基于提供的信息)**:
    ```
    /g:/Projects/deploy/
    ├── utils/
    │   ├── weight/                 # 可能用于存放预训练权重或训练好的模型权重
    │   ├── __pycache__/
    │   ├── class_config.py         # 图像分类模型的配置文件
    │   ├── trainClass.py           # 图像分类模型的训练脚本
    │   ├── trainYolo.py            # YOLO目标检测模型的训练脚本
    │   └── utils.py                # 通用工具函数
    ├── requirements.txt          # 项目依赖文件
    └── data/                       # (建议创建) 存放数据集的目录
        ├── classification/         # 图像分类数据集
        │   ├── train/
        │   │   ├── class_A/
        │   │   │   ├── image1.jpg
        │   │   │   └── ...
        │   │   └── class_B/
        │   │       ├── image2.jpg
        │   │       └── ...
        │   └── val/
        │       ├── class_A/
        │       │   └── ...
        │       └── class_B/
        │           └── ...
        └── object_detection/       # 目标检测数据集
            ├── images/
            │   ├── train/
            │   │   ├── img1.jpg
            │   │   └── ...
            │   └── val/
            │       └── ...
            ├── labels/             # YOLO通常需要这种格式的标签
            │   ├── train/
            │   │   ├── img1.txt
            │   │   └── ...
            │   └── val/
            │       └── ...
            ├── annotations/        # 或者使用PASCAL VOC XML标注
            │   ├── train/
            │   │   ├── img1.xml
            │   │   └── ...
            │   └── val/
            │       └── ...
            └── predefiend_classes.txt # (YOLO可能需要) 类别名称列表
    ```
    建议你创建一个 `data` 目录来存放所有的数据集，并按照任务类型（分类、检测）组织子目录。

## 二、 数据准备

深度学习模型的效果在很大程度上取决于数据的质量和数量。

1.  **图像数据**:
    *   **来源**: 你的图片可以来自公开数据集、自己收集、或者通过 `utils.py` 中的 `download_images` 函数从指定的URL下载。
    *   **格式**: 常见的图片格式如 JPG, PNG 等都可以。
    *   **存放**: 按照上面建议的 `data/` 目录结构存放。

2.  **图像分类数据**:
    *   通常，每个类别一个文件夹，文件夹内存放该类别的所有图片。例如：
        ```
        data/classification/train/dogs/dog1.jpg, dog2.jpg...
        data/classification/train/cats/cat1.jpg, cat2.jpg...
        data/classification/val/dogs/dogX.jpg...
        data/classification/val/cats/catY.jpg...
        ```
    *   `trainClass.py` 脚本会从这些目录中加载图像进行训练。

3.  **目标检测数据**:
    *   **图片**: 存放在 `data/object_detection/images/` 下。
    *   **标注 (Annotations)**: 这是告诉模型图片中物体在哪里、是什么的关键。
        *   **PASCAL VOC XML 格式**: `utils.py` 中的 `generate_annotation` 函数可以生成这种格式的标注文件。你需要提供图片的基本信息 (文件夹、文件名、路径) 以及每个物体的信息 (类别 `sort`，边界框坐标 `xmin, ymin, xmax, ymax`)。
            *   `label_mapping` 字典定义了类别名称到数字ID的映射，例如 `'good': '0'`, `'broke': '1'`。确保你的物体类别与此对应。
            *   生成的XML文件通常与图片放在同一目录下或专门的 `annotations` 目录。
        *   **YOLO 格式**: YOLO模型通常需要 `.txt` 格式的标注文件，每个图片对应一个同名的 `.txt` 文件。每行代表一个物体，格式通常是 `<class_id> <x_center_norm> <y_center_norm> <width_norm> <height_norm>` (坐标是相对于图片宽高归一化的中心点坐标和宽高)。
            *   `trainYolo.py` 脚本会具体说明它期望的标注格式和位置。你需要查阅该脚本或者YOLO框架的文档来准备这种格式的标注。
        *   **工具**: 可以使用 LabelImg, CVAT, LabelMe 等开源工具来手动标注图片。

4.  **阿里云OSS (可选)**:
    如果你的数据或模型存储在阿里云OSS上，`utils.py` 中的 `AliyunOss` 类提供了上传 (`put_object_from_file`)、获取URL (`getUrl`) 和删除 (`delete_object`) 的功能。你需要配置好你的 `access_key_id` 和 `access_key_secret`。

## 三、 模型训练

现在我们来看看如何训练模型。你需要分别对分类模型和目标检测模型进行训练。

### 1. 训练图像分类模型 (`trainClass.py`)

*   **配置文件 (`utils/class_config.py`)**:
    这个文件非常重要，它定义了训练过程中的各种超参数和设置。`CFG` 类是核心配置。你需要关注和修改的参数主要有：
    *   `seed`: 随机种子。
    *   `device`: 训练设备 (`cuda:0` 或 `cpu`)。
    *   `img_size`: 输入图片的尺寸 (例如 `[224, 224]`)。
    *   `train_bs`, `valid_bs`: 训练和验证的批量大小。
    *   `num_classes`: 分类的类别数量，需要与数据集和 `label_mapping` 对应。
    *   `epoch`: 训练的总轮数。
    *   `lr`: 学习率。
    *   `modelName`: 使用的 `timm` 预训练模型名称 (例如 `"vit_base_patch8_224.augreg_in21k"`)。
    *   `pretrained`: 预训练权重的路径。可以是 `timm` 自动下载的权重，也可以是本地的 `.pth` 文件路径 (如 `'/app/utils/weight/best.pth'`)。
    *   `train_path`, `valid_path`: 包含训练/验证XML标注文件的目录列表。

    `class_config.py` 中的辅助函数 (`xml2pd`, `writeTxt` 等) 主要是为 `trainYolo.py` 准备YOLO格式数据。`trainClass.py` 本身基于XML中的对象边界框进行**对象级别**的分类。

*   **运行训练脚本**:
    1.  **准备数据**:
        *   需要XML标注文件，其中 `<object>` 标签定义了要分类的物体，`<path>` 指向实际图片。
        *   `xml2pd` (在 `trainClass.py` 中) 的 `label_mapping` 映射XML中的类别名到数字索引。
    2.  **配置 `utils/class_config.py`**:
        *   设置 `num_classes`, `train_path`, `valid_path`, `modelName`。
        *   决定 `pretrained` 的来源：是自定义的完整模型权重路径，还是希望从 `timm` 加载骨干网络的预训练权重。当前代码期望 `CFG.pretrained` 是一个指向 `Network_Wrapper` 完整权重的路径。如果想用 `timm` 的标准预训练，可能需要调整 `build_model` 函数的逻辑。
    3.  **运行**:
        ```bash
        python utils/trainClass.py
        ```
        模型 (`*_best.pth`, `*_last.pth`) 会保存在运行脚本的当前目录。ONNX模型会保存在 `/app/utils/weight/class.onnx` (注意此硬编码路径)。

    **`trainClass.py` 关键点**:
    *   **模型定义 (`Network_Wrapper`)**: 使用 `timm` 模型作为骨干，添加新的分类头。
    *   **损失函数**: 使用 `LabelSmoothingCrossEntropy`。
    *   **数据增强 (`build_transforms`)**: 使用 `albumentations` 进行丰富的图像增强。
    *   **数据加载 (`xml2pd`, `build_dataset`)**: 从XML中读取对象边界框和标签，然后**裁剪出这些对象区域**进行分类训练。这意味着它不是对整个图像进行分类，而是对图像中的特定对象块进行分类。
    *   **模型保存**: 在 `train` 函数中，最佳验证模型保存为 `f'{CFG.modelName}_best.pth'`。

### 2. 训练目标检测模型 (`trainYolo.py`)

该脚本使用 `ultralytics` YOLO 框架。

*   **数据准备**:
    1.  **XML 转 YOLO 格式**: 使用 `class_config.py` 中的 `xml2txt("你的XML文件夹路径")`。这会生成 `.txt` 格式的标签文件，并按特定结构 (如 `/app/train/yolo/fold0/...`) 存放图像和标签。注意修改 `class_config.py` 中 `xml2pd` 函数内硬编码的输出路径，或确保这些路径可用。
    2.  **创建数据集 YAML (`config.yaml`)**: 此文件告知YOLO数据位置和类别信息。
        ```yaml
        train: /app/train/yolo/fold0/images/train  # 调整为xml2txt的实际输出路径
        val: /app/train/yolo/fold0/images/val    # 调整

        nc: 5  # 类别数，与 class_config.py 中的 label_mapping 一致

        names: ['good', 'broke', 'lose', 'uncovered', 'circle'] # 类别名，顺序与 label_mapping 的索引对应
        ```

*   **训练函数 (`train` in `trainYolo.py`)**:
    *   `model = YOLO("/app/utils/weight/best.pt")`: 加载模型。若从标准YOLO模型开始 (如`yolov8s.pt`)，修改此路径。
    *   `model.train(data='path/to/your/config.yaml', ...)`: 开始训练。

*   **运行训练**:
    可以参考 `yoloRetrain()` 函数，或修改 `trainYolo.py` 使其可直接运行，例如在末尾添加：
    ```python
    if __name__ == '__main__':
        xml_source_dir = "/实际存放XML文件的目录/"
        print(f"处理XML来源: {xml_source_dir}")
        xml2txt(xml_source_dir) # class_config.xml2txt
        print(f"数据已处理到 /app/train/yolo/fold0 (具体路径请检查 class_config.py)")

        dataset_yaml_path = "/app/train/yolo/config.yaml" # 或你的YAML文件路径
        print(f"使用数据集YAML: {dataset_yaml_path}")
        
        print("开始YOLO训练...")
        # 调整epochs, batch, model路径。若全新训练，可使用 "yolov8s.pt"
        # 当前代码 model = YOLO("/app/utils/weight/best.pt") 加载特定文件
        results = train(epochs=50, batch=8, data=dataset_yaml_path) # trainYolo.train
        print("训练完成。")
        print(results)
    ```
    然后运行 `python utils/trainYolo.py`。训练结果通常在 `runs/detect/train/` 目录。

*   **`yolo2dict` 函数**: 用于加载TensorRT优化后的模型进行推理，与训练阶段关系不大。该函数导入了 `YOLOTensorRT` 相关的模块并引用了 `.engine` 文件，这表明项目可能使用了 [triple-Mu/YOLOv8-TensorRT](https://github.com/triple-Mu/YOLOv8-TensorRT) 库中的工具或方法来运行经过TensorRT优化的YOLO模型。

## IV. 模型部署 (概念)

1.  **分类模型**:
    *   `trainClass.py` 中的 `classExport` 可将模型转为ONNX格式。
    *   `buildInferModel` 展示了如何加载ONNX模型。
    *   部署流程：加载ONNX -> 预处理输入 -> 推理 -> 后处理输出。
    *   可导出为ONNX, TensorRT等格式 (`model.export(format='onnx')`)。
    *   **TensorRT 加速 (进阶)**: 对于追求极致推理性能的场景，可以将训练好的YOLO模型 (`.pt` 文件) 先导出为 ONNX 格式，然后利用NVIDIA TensorRT进行优化，生成 `.engine` 文件。项目提及的 [triple-Mu/YOLOv8-TensorRT](https://github.com/triple-Mu/YOLOv8-TensorRT) 库为此类转换和部署提供了代码和工具。`trainYolo.py`中的 `yolo2dict` 函数就暗示了此类用法，它加载了一个 `.engine` 文件，准备使用TensorRT加速的YOLO模型。

2.  **YOLO目标检测模型**:
    *   Ultralytics `.pt` 模型可直接用于推理。
        ```python
        from ultralytics import YOLO
        model = YOLO('path/to/best.pt')
        results = model('image.jpg')
        results.show()
        ```
    *   可导出为ONNX, TensorRT等格式 (`model.export(format='onnx')`)。

3.  **部署环境**:
    可以是Web服务器、移动应用、边缘设备等。`AliyunOss` 类暗示可能使用阿里云。

## V. 使用工具脚本 (`utils.py`)

*   `download_images`: 从URL下载图片。
*   `Network_Wrapper`: PyTorch模块，包装基础模型并添加分类头。
*   `build_model`: 构建和加载分类模型。
*   `AliyunOss`: 与阿里云OSS交互。
*   `generate_annotation`: 生成PASCAL VOC XML标注文件。
*   `indent`: XML格式化辅助。
*   `location2lalo`: 地址到经纬度转换 (高德API)。
*   `log`: 使用 `flask_sse` 的日志函数，可能用于Web UI实时显示。

## 总结给小白

1.  **环境安装**: Python, `requirements.txt` 中的库。
2.  **数据准备**:
    *   **分类 (`trainClass.py`)**: 图片 + XML (描述图片内待分类的对象)。`trainClass.py` 会裁剪这些对象。XML放于 `class_config.py` 中指定的路径。
    *   **检测 (`trainYolo.py`)**: 图片 + XML。运行 `xml2txt` 转为YOLO格式。创建 `dataset.yaml`。
3.  **配置 (`utils/class_config.py`)**:
    *   调整 `CFG.num_classes`, `CFG.train_path`, `CFG.valid_path`, `CFG.modelName`, `CFG.pretrained`。
    *   YOLO: 确保 `xml2pd` 输出路径与YAML文件中的路径一致。
4.  **训练**:
    *   **分类器**: `python utils/trainClass.py`。
    *   **检测器**: `python utils/trainYolo.py` (配置好数据和YAML后)。
5.  **使用模型**: 加载 `.pth`/ONNX (分类) 或 `.pt` (YOLO) 文件进行预测。

**关键后续步骤**:

1.  **理解数据**: 明确分类/检测目标，准备准确的XML。
2.  **逐个攻克**: 先专注一个任务 (分类或检测)。
3.  **检查配置**: 仔细核对 `class_config.py` 和YAML文件，特别是路径。
4.  **运行与调试**: 从小数据集、少轮次开始，检查错误。

项目中很多路径 (如 `/app/...`) 似乎是硬编码的，可能为特定环境 (如Docker) 设计。本地运行时需调整。 